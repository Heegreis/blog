機器學習從統計學開始

統計是從大量資料中找出有意義的資料分布。  
機器學習由機器去幫我們統計。
[readmore]
**目錄**  
[TOC]
# 線性模型
**統計**所觀察與分析的是**變數與變數間的關係**

線性模型是用來敘述資料呈現線性關係的模型。  
也就是在資料的坐標系上若資料分佈散落在某一條直線上，該直線就可以代表該資料集。

線性模型的方程式:  
$y=mx+b$  
[GeoGebra可視化連結](https://www.geogebra.org/graphing/a762zpwj)*(還可以加上一些範例資料點，讓示意圖更完整)*

該數學式代表了一條直線，而我們就是要調整 $m$ 與 $b$ 這兩個參數，來得到最符合資料分佈的直線。
# 線性回歸
我們可以透過線性回歸的方式來找到這條直線。

直觀來說，這條線會是: 每個點到該直線的距離總和，會最小。  
而點到線的距離，可以去計算點到線的垂直距離。

但一般來說我們會假設 $x$ 是真實資料，$y$ 是預測資料，所以可以改為去計算y軸上點到直線的距離。

這些總和出的距離就是該直線的**誤差**。
而距離的計算方式為**相減後平方**，在電腦運算上相對於取絕對值的計算量較小。

**誤差函數 Loss function**:  
$Loss(x, y) = sum( (y' - y)^2 ) = sum( ( (mx + b) - y)^2 )$

有了計算直線的誤差有多少的公式後，就是要找出那條直線的誤差值會最小。也就是哪一組 $m$ 和 $b$ 會得到最小的誤差。

簡單的方法可以用 gradient descent(梯度下降法)，我們以 $m$ 和 $b$ 分別作為x軸和y軸，計算出的 loss值為z軸。在該三維座標系中所畫出的圖形，最小 loss值就是最低點的位置。

線性模型+最小平方法
# 參考資料
[[Day 02] 解構linear regression - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10186338)

*最後編輯時間:2019/6/20*

<!--tags:
-->
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTg3MzI0MjQ4OSwxMzE3MTk3MzM1LC01MD
k0NDMwNjIsLTQ4NzMzMDQ4NCwyMDIxMDc5NjA3LC03MTA2MDE5
NTUsLTExNzc0NDk2NjEsMTkzNDQ3MTg2MywtMTcwNjAwODAxNy
w3MzE5NjI3NjksMTMyNDQxMDU5NSw3MTg0MzQ3MTcsMTc0NDM2
NDA5M119
-->